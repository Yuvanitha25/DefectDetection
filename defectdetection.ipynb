{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3209332,"sourceType":"datasetVersion","datasetId":1946896},{"sourceId":13081301,"sourceType":"datasetVersion","datasetId":8285117}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:55:40.952931Z","iopub.execute_input":"2025-09-18T04:55:40.953146Z","iopub.status.idle":"2025-09-18T04:55:56.212736Z","shell.execute_reply.started":"2025-09-18T04:55:40.953122Z","shell.execute_reply":"2025-09-18T04:55:56.212010Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers, callbacks\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport matplotlib.pyplot as plt\nimport pathlib\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:26:01.243775Z","iopub.execute_input":"2025-09-18T05:26:01.244362Z","iopub.status.idle":"2025-09-18T05:26:01.248612Z","shell.execute_reply.started":"2025-09-18T05:26:01.244341Z","shell.execute_reply":"2025-09-18T05:26:01.248019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = (224, 224)\nBATCH_SIZE = 16\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:23.491050Z","iopub.execute_input":"2025-09-18T04:57:23.491530Z","iopub.status.idle":"2025-09-18T04:57:23.495374Z","shell.execute_reply.started":"2025-09-18T04:57:23.491487Z","shell.execute_reply":"2025-09-18T04:57:23.494696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"directory = \"/kaggle/input/mvtec-ad\"\nroot = pathlib.Path(directory)\nclasses = sorted([p.name for p in root.iterdir() if p.is_dir()])\nprint(\"Detected classes:\", classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:24.073363Z","iopub.execute_input":"2025-09-18T04:57:24.074158Z","iopub.status.idle":"2025-09-18T04:57:24.091412Z","shell.execute_reply.started":"2025-09-18T04:57:24.074126Z","shell.execute_reply":"2025-09-18T04:57:24.090880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filepaths, labels = [], []\nfor cls in classes:\n    for img_path in (root / cls).rglob(\"*\"):\n        if img_path.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]:\n            filepaths.append(str(img_path))\n            labels.append(cls)\n\nprint(\"Total images:\", len(filepaths))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:26.131170Z","iopub.execute_input":"2025-09-18T04:57:26.131452Z","iopub.status.idle":"2025-09-18T04:57:28.286693Z","shell.execute_reply.started":"2025-09-18T04:57:26.131431Z","shell.execute_reply":"2025-09-18T04:57:28.285931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_paths, test_paths, train_labels, test_labels = train_test_split(\n    filepaths, labels, test_size=0.2, random_state=42, stratify=labels\n)\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    train_paths, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n)\nprint(\"Train:\", len(train_paths), \"Val:\", len(val_paths), \"Test:\", len(test_paths))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:30.203846Z","iopub.execute_input":"2025-09-18T04:57:30.204537Z","iopub.status.idle":"2025-09-18T04:57:30.233390Z","shell.execute_reply.started":"2025-09-18T04:57:30.204489Z","shell.execute_reply":"2025-09-18T04:57:30.232691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = classes\nclass_to_index = {c: i for i, c in enumerate(class_names)}\nnum_classes = len(class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:31.671901Z","iopub.execute_input":"2025-09-18T04:57:31.672156Z","iopub.status.idle":"2025-09-18T04:57:31.675983Z","shell.execute_reply.started":"2025-09-18T04:57:31.672138Z","shell.execute_reply":"2025-09-18T04:57:31.675360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_and_preprocess(path, label):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n    img.set_shape([None, None, 3])\n    img = tf.image.resize(img, IMG_SIZE)\n    img = tf.cast(img, tf.float32) / 255.0\n    return img, label\n\ndef augment(img, label):\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_brightness(img, 0.08)\n    img = tf.image.random_contrast(img, 0.9, 1.1)\n    return img, label\n\ndef paths_to_dataset(paths, labels, shuffle=False, augment_data=False):\n    labels_idx = [class_to_index[l] for l in labels]\n    ds = tf.data.Dataset.from_tensor_slices((paths, labels_idx))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(paths))\n    ds = ds.map(lambda p, l: load_and_preprocess(p, l), num_parallel_calls=AUTOTUNE)\n    if augment_data:\n        ds = ds.map(augment, num_parallel_calls=AUTOTUNE)\n    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:34.580189Z","iopub.execute_input":"2025-09-18T04:57:34.580743Z","iopub.status.idle":"2025-09-18T04:57:34.586684Z","shell.execute_reply.started":"2025-09-18T04:57:34.580718Z","shell.execute_reply":"2025-09-18T04:57:34.585954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = paths_to_dataset(train_paths, train_labels, shuffle=True, augment_data=True)\nval_ds = paths_to_dataset(val_paths, val_labels)\n#test_ds = paths_to_dataset(test_paths, test_labels)\n#train_ds\ndata_dir = directory\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    data_dir,\n    labels=\"inferred\",\n    label_mode=\"int\",   # integer labels\n    image_size=(224, 224),\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:40.789075Z","iopub.execute_input":"2025-09-18T04:57:40.789800Z","iopub.status.idle":"2025-09-18T04:57:43.217397Z","shell.execute_reply.started":"2025-09-18T04:57:40.789776Z","shell.execute_reply":"2025-09-18T04:57:43.216530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\nbase.trainable = False\n\ninputs = layers.Input(shape=(224, 224, 3))\nx = preprocess_input(inputs)\nx = base(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(256, activation=\"relu\")(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\nmodel = Model(inputs, outputs)\nmodel.compile(optimizer=optimizers.Adam(1e-3),\n              loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:57:51.393797Z","iopub.execute_input":"2025-09-18T04:57:51.394358Z","iopub.status.idle":"2025-09-18T04:57:54.467017Z","shell.execute_reply.started":"2025-09-18T04:57:51.394334Z","shell.execute_reply":"2025-09-18T04:57:54.466405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cb = [\n    callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n    callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:58:03.177890Z","iopub.execute_input":"2025-09-18T04:58:03.178154Z","iopub.status.idle":"2025-09-18T04:58:03.182290Z","shell.execute_reply.started":"2025-09-18T04:58:03.178135Z","shell.execute_reply":"2025-09-18T04:58:03.181553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history1 = model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=cb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:58:04.461106Z","iopub.execute_input":"2025-09-18T04:58:04.461826Z","iopub.status.idle":"2025-09-18T05:05:17.597653Z","shell.execute_reply.started":"2025-09-18T04:58:04.461801Z","shell.execute_reply":"2025-09-18T05:05:17.597045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in base.layers[-30:]:\n    layer.trainable = True\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"sparse_categorical_crossentropy\",  # <-- use sparse\n    metrics=[\"accuracy\"]\n)\n\nhistory2 = model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=cb)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:05:29.436798Z","iopub.execute_input":"2025-09-18T05:05:29.437329Z","iopub.status.idle":"2025-09-18T05:12:35.407759Z","shell.execute_reply.started":"2025-09-18T05:05:29.437306Z","shell.execute_reply":"2025-09-18T05:12:35.407127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_weights(\"best_model.h5\")\ny_true, y_pred = [], []\nfor imgs, labels in test_ds:\n    preds = model.predict(imgs, verbose=0)\n    y_pred.extend(np.argmax(preds, axis=1))\n    y_true.extend(labels.numpy())\n\nprint(classification_report(y_true, y_pred, target_names=class_names))\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\nacc = accuracy_score(y_true, y_pred)\nprint(\"Accuracy score:\", acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:26:11.240035Z","iopub.execute_input":"2025-09-18T05:26:11.240516Z","iopub.status.idle":"2025-09-18T05:27:04.953193Z","shell.execute_reply.started":"2025-09-18T05:26:11.240475Z","shell.execute_reply":"2025-09-18T05:27:04.952418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Paths\ndata_dir = directory  # your dataset root\n\n# Data generators with augmentation for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2  # 20% data for validation\n)\n\n# Train generator\ntrain_generator = train_datagen.flow_from_directory(\n    data_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=\"categorical\",  # <-- one-hot labels\n    subset=\"training\"\n)\n\n# Validation generator\nval_generator = train_datagen.flow_from_directory(\n    data_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Optional: separate test split (if you want an unseen set)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_directory(\n    data_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='sparse',\n    shuffle=False  # important for evaluation\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:28:33.551303Z","iopub.execute_input":"2025-09-18T05:28:33.551666Z","iopub.status.idle":"2025-09-18T05:28:34.555024Z","shell.execute_reply.started":"2025-09-18T05:28:33.551643Z","shell.execute_reply":"2025-09-18T05:28:34.554480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#show_gradcam(test_paths[0], model, layer=\"resnet50_conv5_block3_out\")\n# Evaluate on test data\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(\"Test Accuracy:\", test_acc)\nprint(\"Test Loss:\", test_loss)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:28:37.304952Z","iopub.execute_input":"2025-09-18T05:28:37.305244Z","iopub.status.idle":"2025-09-18T05:31:39.469027Z","shell.execute_reply.started":"2025-09-18T05:28:37.305223Z","shell.execute_reply":"2025-09-18T05:31:39.468438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"medicinal_leaf_model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:32:21.744459Z","iopub.execute_input":"2025-09-18T05:32:21.745038Z","iopub.status.idle":"2025-09-18T05:32:22.355706Z","shell.execute_reply.started":"2025-09-18T05:32:21.745015Z","shell.execute_reply":"2025-09-18T05:32:22.355133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\n\n# path to your test image\nimg_path = \"/kaggle/input/mvtec-ad/pill/test/color/000.png\"\n# Load and preprocess\nimg = image.load_img(img_path, target_size=(224, 224))\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)  # add batch dimension\nimg_array = img_array / 255.0  # normalize same as training\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:32:24.500967Z","iopub.execute_input":"2025-09-18T05:32:24.501715Z","iopub.status.idle":"2025-09-18T05:32:24.533463Z","shell.execute_reply.started":"2025-09-18T05:32:24.501692Z","shell.execute_reply":"2025-09-18T05:32:24.532952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = model.predict(img_array)\npred_class = np.argmax(pred, axis=1)[0]\n\nprint(\"Predicted class index:\", pred_class)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:32:27.090964Z","iopub.execute_input":"2025-09-18T05:32:27.091198Z","iopub.status.idle":"2025-09-18T05:32:29.506506Z","shell.execute_reply.started":"2025-09-18T05:32:27.091182Z","shell.execute_reply":"2025-09-18T05:32:29.505906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# If you used ImageDataGenerator\nclass_indices = train_generator.class_indices  # dictionary\nclasses = list(class_indices.keys())\n\n# OR if you used image_dataset_from_directory\n#classes = train_ds.class_names\n\nprint(\"Predicted class:\", classes[pred_class])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:32:32.203741Z","iopub.execute_input":"2025-09-18T05:32:32.204043Z","iopub.status.idle":"2025-09-18T05:32:32.209968Z","shell.execute_reply.started":"2025-09-18T05:32:32.204014Z","shell.execute_reply":"2025-09-18T05:32:32.209121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\n\n# Root dataset folder (update this to your dataset location)\ndataset_dir = \"/kaggle/input/mvtec-ad\"\n\n# Get class names in the same order as training\n# If you used ImageDataGenerator\nclasses = list(train_generator.class_indices.keys())\n# OR if you used image_dataset_from_directory\n#classes = train_ds.class_names\n\n# Loop through each top-level category (bottle, capsule, cable, ...)\ncategories = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n\nfor category in categories:\n    test_dir = os.path.join(dataset_dir, category, \"test\")\n    if os.path.exists(test_dir):\n        print(f\"\\n=== Category: {category} ===\")\n        \n        # Loop through each defect type inside test (e.g. \"good\", \"broken_large\", etc.)\n        sub_classes = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]\n        \n        for sub in sub_classes:\n            sub_path = os.path.join(test_dir, sub)\n            image_files = [f for f in os.listdir(sub_path) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n            \n            # Just test the first image for demonstration\n            if image_files:\n                img_path = os.path.join(sub_path, image_files[0])\n                \n                # Load and preprocess\n                img = image.load_img(img_path, target_size=(224, 224))\n                img_array = image.img_to_array(img)\n                img_array = np.expand_dims(img_array, axis=0) / 255.0\n                \n                # Predict\n                pred = model.predict(img_array, verbose=0)\n                pred_class = np.argmax(pred, axis=1)[0]\n                \n                print(f\"  Subclass: {sub:20s} â†’ Predicted: {classes[pred_class]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:32:33.706197Z","iopub.execute_input":"2025-09-18T05:32:33.706459Z","iopub.status.idle":"2025-09-18T05:32:43.938026Z","shell.execute_reply.started":"2025-09-18T05:32:33.706439Z","shell.execute_reply":"2025-09-18T05:32:43.937364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\n\n# Root dataset folder\ndataset_dir = \"/kaggle/input/mvtec-ad\"\n\n# Class names (from your training set)\n#classes = train_ds.class_names  \n# or \nclasses= list(train_generator.class_indices.keys())\n\n\n# Loop through categories\ncategories = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n\nfor category in categories:\n    test_dir = os.path.join(dataset_dir, category, \"test\")\n    if os.path.exists(test_dir):\n        print(f\"\\n=== Category: {category} ===\")\n\n        sub_classes = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]\n        \n        for sub in sub_classes:\n            sub_path = os.path.join(test_dir, sub)\n            image_files = [f for f in os.listdir(sub_path) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n\n            # Show up to 12 images in a grid (4x3)\n            n_show = min(12, len(image_files))\n            if n_show == 0:\n                continue\n\n            plt.figure(figsize=(12, 9))\n            for i, img_file in enumerate(image_files[:n_show]):\n                img_path = os.path.join(sub_path, img_file)\n\n                # Preprocess image\n                img = image.load_img(img_path, target_size=(224, 224))\n                img_array = image.img_to_array(img)\n                img_array = np.expand_dims(img_array, axis=0) / 255.0\n\n                # Predict\n                pred = model.predict(img_array, verbose=0)\n                pred_class = np.argmax(pred, axis=1)[0]\n\n                # Plot\n                plt.subplot(3, 4, i+1)  # 3 rows x 4 cols\n                plt.imshow(image.load_img(img_path))\n                plt.title(f\"True: {sub}\\nPred: {classes[pred_class]}\", fontsize=9)\n                plt.axis(\"off\")\n\n            plt.suptitle(f\"{category} / {sub}\", fontsize=12, weight=\"bold\")\n            plt.tight_layout()\n            plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-09-18T05:34:35.775856Z","iopub.execute_input":"2025-09-18T05:34:35.776452Z","iopub.status.idle":"2025-09-18T05:40:00.865199Z","shell.execute_reply.started":"2025-09-18T05:34:35.776426Z","shell.execute_reply":"2025-09-18T05:40:00.864084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\nimport os\n\n# Path to a folder with images (not your dataset)\nrandom_img_folder = \"/kaggle/input/my-random-images1\"  # change this to your folder\n\n# Collect all image file paths\nall_images = []\nfor root, dirs, files in os.walk(random_img_folder):\n    for file in files:\n        if file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n            all_images.append(os.path.join(root, file))\n\n# Pick a random image\nimg_path = random.choice(all_images)\n\n# Load and show\nimg = image.load_img(img_path)  # no resizing\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(\"Random Image\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T05:40:11.969725Z","iopub.execute_input":"2025-09-18T05:40:11.969982Z","iopub.status.idle":"2025-09-18T05:40:12.100191Z","shell.execute_reply.started":"2025-09-18T05:40:11.969964Z","shell.execute_reply":"2025-09-18T05:40:12.099521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}